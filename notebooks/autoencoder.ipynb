{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "from torch.nn import MSELoss\n",
    "from functools import partial\n",
    "from src.models.autoencoder import Autoencoder\n",
    "from src.data.utils import collate_batch\n",
    "from src.data.load import load_data\n",
    "from src.models.utils import *\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"autoencoder.log\", encoding=\"utf-8\", level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105231750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(21)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_data(\"../data/processed/\")\n",
    "tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "vocab = torch.load(\"../data/vocab.pt\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(collate_batch, vocab=vocab, tokenizer=tokenizer),\n",
    "    sampler=train_dataset.get_sampler(),\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(collate_batch, vocab=vocab, tokenizer=tokenizer),\n",
    "    sampler=val_dataset.get_sampler(),\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=partial(collate_batch, vocab=vocab, tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "\n",
    "configs = [{\"embed_dim\":128}, {\"embed_dim\":256}, {\"embed_dim\":512}]\n",
    "\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/ 2795 batches | loss 0.000970\n",
      "| epoch   1 |  2000/ 2795 batches | loss 0.000166\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  7.18s | train loss 0.000568 | validation loss 0.000120 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |  1000/ 2795 batches | loss 0.000105\n",
      "| epoch   2 |  2000/ 2795 batches | loss 0.000095\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  6.79s | train loss 0.000100 | validation loss 0.000094 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |  1000/ 2795 batches | loss 0.000085\n",
      "| epoch   3 |  2000/ 2795 batches | loss 0.000082\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  6.71s | train loss 0.000084 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |  1000/ 2795 batches | loss 0.000077\n",
      "| epoch   4 |  2000/ 2795 batches | loss 0.000075\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  6.66s | train loss 0.000076 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |  1000/ 2795 batches | loss 0.000072\n",
      "| epoch   5 |  2000/ 2795 batches | loss 0.000070\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  6.56s | train loss 0.000071 | validation loss 0.000077 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |  1000/ 2795 batches | loss 0.000068\n",
      "| epoch   6 |  2000/ 2795 batches | loss 0.000067\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  6.61s | train loss 0.000067 | validation loss 0.000073 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |  1000/ 2795 batches | loss 0.000064\n",
      "| epoch   7 |  2000/ 2795 batches | loss 0.000065\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  6.86s | train loss 0.000065 | validation loss 0.000070 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |  1000/ 2795 batches | loss 0.000063\n",
      "| epoch   8 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  7.02s | train loss 0.000062 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch   9 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  6.75s | train loss 0.000060 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  10 |  2000/ 2795 batches | loss 0.000057\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  6.83s | train loss 0.000058 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |  1000/ 2795 batches | loss 0.000056\n",
      "| epoch  11 |  2000/ 2795 batches | loss 0.000056\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  6.71s | train loss 0.000056 | validation loss 0.000059 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |  1000/ 2795 batches | loss 0.000056\n",
      "| epoch  12 |  2000/ 2795 batches | loss 0.000054\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  6.91s | train loss 0.000055 | validation loss 0.000059 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |  1000/ 2795 batches | loss 0.000054\n",
      "| epoch  13 |  2000/ 2795 batches | loss 0.000053\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  6.62s | train loss 0.000053 | validation loss 0.000056 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |  1000/ 2795 batches | loss 0.000052\n",
      "| epoch  14 |  2000/ 2795 batches | loss 0.000052\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  6.63s | train loss 0.000052 | validation loss 0.000057 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |  1000/ 2795 batches | loss 0.000051\n",
      "| epoch  15 |  2000/ 2795 batches | loss 0.000050\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  6.71s | train loss 0.000051 | validation loss 0.000056 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |  1000/ 2795 batches | loss 0.000050\n",
      "| epoch  16 |  2000/ 2795 batches | loss 0.000050\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  6.55s | train loss 0.000050 | validation loss 0.000054 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |  1000/ 2795 batches | loss 0.000049\n",
      "| epoch  17 |  2000/ 2795 batches | loss 0.000049\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time: 10.10s | train loss 0.000049 | validation loss 0.000054 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |  1000/ 2795 batches | loss 0.000048\n",
      "| epoch  18 |  2000/ 2795 batches | loss 0.000048\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time: 10.21s | train loss 0.000048 | validation loss 0.000052 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |  1000/ 2795 batches | loss 0.000048\n",
      "| epoch  19 |  2000/ 2795 batches | loss 0.000046\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time: 10.17s | train loss 0.000047 | validation loss 0.000052 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |  1000/ 2795 batches | loss 0.000046\n",
      "| epoch  20 |  2000/ 2795 batches | loss 0.000046\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time: 10.05s | train loss 0.000046 | validation loss 0.000051 \n",
      "-----------------------------------------------------------\n",
      "| epoch  21 |  1000/ 2795 batches | loss 0.000046\n",
      "| epoch  21 |  2000/ 2795 batches | loss 0.000046\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  21 | time:  9.98s | train loss 0.000046 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  22 |  1000/ 2795 batches | loss 0.000046\n",
      "| epoch  22 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  22 | time:  9.90s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  23 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  23 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  23 | time:  9.84s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  24 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  24 |  2000/ 2795 batches | loss 0.000046\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  24 | time: 10.08s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  25 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  25 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  25 | time: 10.05s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  26 |  1000/ 2795 batches | loss 0.000046\n",
      "| epoch  26 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  26 | time:  9.98s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  27 |  1000/ 2795 batches | loss 0.000046\n",
      "| epoch  27 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  27 | time:  9.96s | train loss 0.000046 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  28 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  28 |  2000/ 2795 batches | loss 0.000046\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  28 | time: 10.11s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  29 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  29 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  29 | time:  9.90s | train loss 0.000045 | validation loss 0.000051 \n",
      "-----------------------------------------------------------\n",
      "| epoch  30 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  30 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  30 | time:  9.91s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  31 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  31 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  31 | time:  9.87s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  32 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  32 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  32 | time:  9.90s | train loss 0.000045 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  33 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  33 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  33 | time:  9.99s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  34 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  34 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  34 | time: 10.02s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  35 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  35 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  35 | time:  9.90s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  36 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  36 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  36 | time: 10.03s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  37 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  37 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  37 | time: 10.03s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  38 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  38 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  38 | time: 11.33s | train loss 0.000045 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  39 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  39 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  39 | time:  9.92s | train loss 0.000044 | validation loss 0.000051 \n",
      "-----------------------------------------------------------\n",
      "| epoch  40 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  40 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  40 | time:  9.95s | train loss 0.000044 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  41 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  41 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  41 | time: 10.03s | train loss 0.000044 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  42 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  42 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  42 | time: 10.04s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  43 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  43 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  43 | time: 10.02s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  44 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  44 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  44 | time: 10.05s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  45 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  45 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  45 | time: 10.13s | train loss 0.000044 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  46 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  46 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  46 | time: 10.03s | train loss 0.000044 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  47 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  47 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  47 | time:  9.83s | train loss 0.000045 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  48 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  48 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  48 | time: 10.10s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  49 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  49 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  49 | time: 10.44s | train loss 0.000045 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  50 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  50 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  50 | time: 10.06s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  51 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  51 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  51 | time: 10.47s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  52 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  52 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  52 | time: 10.01s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  53 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  53 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  53 | time: 10.55s | train loss 0.000045 | validation loss 0.000047 \n",
      "-----------------------------------------------------------\n",
      "| epoch  54 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  54 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  54 | time: 10.06s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  55 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  55 |  2000/ 2795 batches | loss 0.000045\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  55 | time: 10.48s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  56 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  56 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  56 | time: 10.00s | train loss 0.000044 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  57 |  1000/ 2795 batches | loss 0.000045\n",
      "| epoch  57 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  57 | time: 10.32s | train loss 0.000044 | validation loss 0.000049 \n",
      "-----------------------------------------------------------\n",
      "| epoch  58 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  58 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  58 | time:  9.86s | train loss 0.000044 | validation loss 0.000050 \n",
      "-----------------------------------------------------------\n",
      "| epoch  59 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  59 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  59 | time: 10.40s | train loss 0.000044 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "| epoch  60 |  1000/ 2795 batches | loss 0.000044\n",
      "| epoch  60 |  2000/ 2795 batches | loss 0.000044\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  60 | time: 10.00s | train loss 0.000044 | validation loss 0.000048 \n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test loss 0.000045\n",
      "| epoch   1 |  1000/ 2795 batches | loss 0.001315\n",
      "| epoch   1 |  2000/ 2795 batches | loss 0.000220\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 12.91s | train loss 0.000768 | validation loss 0.000175 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |  1000/ 2795 batches | loss 0.000153\n",
      "| epoch   2 |  2000/ 2795 batches | loss 0.000141\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 13.27s | train loss 0.000147 | validation loss 0.000133 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |  1000/ 2795 batches | loss 0.000124\n",
      "| epoch   3 |  2000/ 2795 batches | loss 0.000119\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 12.33s | train loss 0.000122 | validation loss 0.000119 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |  1000/ 2795 batches | loss 0.000109\n",
      "| epoch   4 |  2000/ 2795 batches | loss 0.000106\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 12.76s | train loss 0.000107 | validation loss 0.000107 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |  1000/ 2795 batches | loss 0.000103\n",
      "| epoch   5 |  2000/ 2795 batches | loss 0.000100\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 12.21s | train loss 0.000101 | validation loss 0.000102 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |  1000/ 2795 batches | loss 0.000097\n",
      "| epoch   6 |  2000/ 2795 batches | loss 0.000094\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 12.22s | train loss 0.000095 | validation loss 0.000098 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |  1000/ 2795 batches | loss 0.000092\n",
      "| epoch   7 |  2000/ 2795 batches | loss 0.000089\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 12.88s | train loss 0.000090 | validation loss 0.000093 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |  1000/ 2795 batches | loss 0.000087\n",
      "| epoch   8 |  2000/ 2795 batches | loss 0.000087\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 12.43s | train loss 0.000087 | validation loss 0.000088 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |  1000/ 2795 batches | loss 0.000083\n",
      "| epoch   9 |  2000/ 2795 batches | loss 0.000083\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 12.13s | train loss 0.000083 | validation loss 0.000091 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  10 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 12.56s | train loss 0.000079 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |  1000/ 2795 batches | loss 0.000077\n",
      "| epoch  11 |  2000/ 2795 batches | loss 0.000077\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time: 12.56s | train loss 0.000077 | validation loss 0.000076 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |  1000/ 2795 batches | loss 0.000077\n",
      "| epoch  12 |  2000/ 2795 batches | loss 0.000076\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time: 12.81s | train loss 0.000076 | validation loss 0.000075 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |  1000/ 2795 batches | loss 0.000075\n",
      "| epoch  13 |  2000/ 2795 batches | loss 0.000071\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time: 12.32s | train loss 0.000073 | validation loss 0.000073 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |  1000/ 2795 batches | loss 0.000070\n",
      "| epoch  14 |  2000/ 2795 batches | loss 0.000069\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time: 12.42s | train loss 0.000069 | validation loss 0.000073 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |  1000/ 2795 batches | loss 0.000069\n",
      "| epoch  15 |  2000/ 2795 batches | loss 0.000067\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time: 13.00s | train loss 0.000068 | validation loss 0.000069 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |  1000/ 2795 batches | loss 0.000066\n",
      "| epoch  16 |  2000/ 2795 batches | loss 0.000066\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time: 12.08s | train loss 0.000066 | validation loss 0.000068 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |  1000/ 2795 batches | loss 0.000065\n",
      "| epoch  17 |  2000/ 2795 batches | loss 0.000064\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time: 12.31s | train loss 0.000065 | validation loss 0.000070 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |  1000/ 2795 batches | loss 0.000065\n",
      "| epoch  18 |  2000/ 2795 batches | loss 0.000062\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time: 12.82s | train loss 0.000063 | validation loss 0.000067 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |  1000/ 2795 batches | loss 0.000065\n",
      "| epoch  19 |  2000/ 2795 batches | loss 0.000063\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time: 12.23s | train loss 0.000064 | validation loss 0.000066 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |  1000/ 2795 batches | loss 0.000061\n",
      "| epoch  20 |  2000/ 2795 batches | loss 0.000063\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time: 12.82s | train loss 0.000062 | validation loss 0.000067 \n",
      "-----------------------------------------------------------\n",
      "| epoch  21 |  1000/ 2795 batches | loss 0.000062\n",
      "| epoch  21 |  2000/ 2795 batches | loss 0.000062\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  21 | time: 12.52s | train loss 0.000062 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  22 |  1000/ 2795 batches | loss 0.000061\n",
      "| epoch  22 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  22 | time: 12.29s | train loss 0.000061 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  23 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  23 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  23 | time: 12.38s | train loss 0.000061 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  24 |  1000/ 2795 batches | loss 0.000063\n",
      "| epoch  24 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  24 | time: 12.23s | train loss 0.000062 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  25 |  1000/ 2795 batches | loss 0.000062\n",
      "| epoch  25 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  25 | time: 12.38s | train loss 0.000061 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  26 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  26 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  26 | time: 14.08s | train loss 0.000059 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  27 |  1000/ 2795 batches | loss 0.000061\n",
      "| epoch  27 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  27 | time: 12.30s | train loss 0.000060 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  28 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  28 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  28 | time: 12.50s | train loss 0.000061 | validation loss 0.000066 \n",
      "-----------------------------------------------------------\n",
      "| epoch  29 |  1000/ 2795 batches | loss 0.000061\n",
      "| epoch  29 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  29 | time: 12.93s | train loss 0.000060 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  30 |  1000/ 2795 batches | loss 0.000061\n",
      "| epoch  30 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  30 | time: 12.37s | train loss 0.000060 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  31 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  31 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  31 | time: 12.21s | train loss 0.000060 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  32 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  32 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  32 | time: 12.83s | train loss 0.000060 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  33 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  33 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  33 | time: 12.43s | train loss 0.000060 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  34 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  34 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  34 | time: 12.27s | train loss 0.000060 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  35 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  35 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  35 | time: 12.28s | train loss 0.000059 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  36 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  36 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  36 | time: 12.54s | train loss 0.000059 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  37 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  37 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  37 | time: 12.82s | train loss 0.000059 | validation loss 0.000061 \n",
      "-----------------------------------------------------------\n",
      "| epoch  38 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  38 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  38 | time: 12.35s | train loss 0.000060 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  39 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  39 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  39 | time: 12.50s | train loss 0.000059 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  40 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  40 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  40 | time: 12.90s | train loss 0.000059 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  41 |  1000/ 2795 batches | loss 0.000057\n",
      "| epoch  41 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  41 | time: 12.23s | train loss 0.000058 | validation loss 0.000061 \n",
      "-----------------------------------------------------------\n",
      "| epoch  42 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  42 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  42 | time: 12.26s | train loss 0.000059 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  43 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  43 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  43 | time: 12.36s | train loss 0.000059 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  44 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  44 |  2000/ 2795 batches | loss 0.000061\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  44 | time: 12.47s | train loss 0.000060 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  45 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  45 |  2000/ 2795 batches | loss 0.000058\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  45 | time: 12.25s | train loss 0.000059 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  46 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  46 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  46 | time: 12.15s | train loss 0.000059 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  47 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  47 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  47 | time: 12.45s | train loss 0.000060 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  48 |  1000/ 2795 batches | loss 0.000057\n",
      "| epoch  48 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  48 | time: 12.99s | train loss 0.000058 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  49 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  49 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  49 | time: 12.58s | train loss 0.000059 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  50 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  50 |  2000/ 2795 batches | loss 0.000058\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  50 | time: 12.57s | train loss 0.000059 | validation loss 0.000063 \n",
      "-----------------------------------------------------------\n",
      "| epoch  51 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  51 |  2000/ 2795 batches | loss 0.000058\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  51 | time: 12.93s | train loss 0.000058 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  52 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  52 |  2000/ 2795 batches | loss 0.000058\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  52 | time: 12.21s | train loss 0.000059 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  53 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  53 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  53 | time: 12.33s | train loss 0.000059 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  54 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  54 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  54 | time: 12.56s | train loss 0.000059 | validation loss 0.000061 \n",
      "-----------------------------------------------------------\n",
      "| epoch  55 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  55 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  55 | time: 12.35s | train loss 0.000059 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  56 |  1000/ 2795 batches | loss 0.000060\n",
      "| epoch  56 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  56 | time: 12.42s | train loss 0.000059 | validation loss 0.000061 \n",
      "-----------------------------------------------------------\n",
      "| epoch  57 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  57 |  2000/ 2795 batches | loss 0.000059\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  57 | time: 12.49s | train loss 0.000059 | validation loss 0.000064 \n",
      "-----------------------------------------------------------\n",
      "| epoch  58 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  58 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  58 | time: 12.47s | train loss 0.000059 | validation loss 0.000065 \n",
      "-----------------------------------------------------------\n",
      "| epoch  59 |  1000/ 2795 batches | loss 0.000059\n",
      "| epoch  59 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  59 | time: 13.25s | train loss 0.000060 | validation loss 0.000062 \n",
      "-----------------------------------------------------------\n",
      "| epoch  60 |  1000/ 2795 batches | loss 0.000058\n",
      "| epoch  60 |  2000/ 2795 batches | loss 0.000060\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  60 | time: 13.08s | train loss 0.000059 | validation loss 0.000061 \n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test loss 0.000063\n",
      "| epoch   1 |  1000/ 2795 batches | loss 0.004678\n",
      "| epoch   1 |  2000/ 2795 batches | loss 0.000599\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 16.98s | train loss 0.002639 | validation loss 0.000465 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |  1000/ 2795 batches | loss 0.000422\n",
      "| epoch   2 |  2000/ 2795 batches | loss 0.000353\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 17.25s | train loss 0.000388 | validation loss 0.000295 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |  1000/ 2795 batches | loss 0.000269\n",
      "| epoch   3 |  2000/ 2795 batches | loss 0.000239\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 17.11s | train loss 0.000254 | validation loss 0.000211 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |  1000/ 2795 batches | loss 0.000200\n",
      "| epoch   4 |  2000/ 2795 batches | loss 0.000185\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 17.10s | train loss 0.000192 | validation loss 0.000173 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |  1000/ 2795 batches | loss 0.000164\n",
      "| epoch   5 |  2000/ 2795 batches | loss 0.000157\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 17.38s | train loss 0.000160 | validation loss 0.000150 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |  1000/ 2795 batches | loss 0.000144\n",
      "| epoch   6 |  2000/ 2795 batches | loss 0.000141\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 17.06s | train loss 0.000143 | validation loss 0.000139 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |  1000/ 2795 batches | loss 0.000130\n",
      "| epoch   7 |  2000/ 2795 batches | loss 0.000128\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 17.66s | train loss 0.000129 | validation loss 0.000128 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |  1000/ 2795 batches | loss 0.000124\n",
      "| epoch   8 |  2000/ 2795 batches | loss 0.000120\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 17.71s | train loss 0.000122 | validation loss 0.000120 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |  1000/ 2795 batches | loss 0.000117\n",
      "| epoch   9 |  2000/ 2795 batches | loss 0.000114\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 17.88s | train loss 0.000116 | validation loss 0.000115 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |  1000/ 2795 batches | loss 0.000111\n",
      "| epoch  10 |  2000/ 2795 batches | loss 0.000110\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 17.14s | train loss 0.000110 | validation loss 0.000112 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |  1000/ 2795 batches | loss 0.000107\n",
      "| epoch  11 |  2000/ 2795 batches | loss 0.000105\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time: 17.10s | train loss 0.000106 | validation loss 0.000107 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |  1000/ 2795 batches | loss 0.000104\n",
      "| epoch  12 |  2000/ 2795 batches | loss 0.000103\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time: 16.78s | train loss 0.000103 | validation loss 0.000103 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |  1000/ 2795 batches | loss 0.000098\n",
      "| epoch  13 |  2000/ 2795 batches | loss 0.000098\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time: 17.32s | train loss 0.000098 | validation loss 0.000100 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |  1000/ 2795 batches | loss 0.000096\n",
      "| epoch  14 |  2000/ 2795 batches | loss 0.000094\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time: 17.34s | train loss 0.000095 | validation loss 0.000098 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |  1000/ 2795 batches | loss 0.000092\n",
      "| epoch  15 |  2000/ 2795 batches | loss 0.000093\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time: 16.86s | train loss 0.000092 | validation loss 0.000096 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |  1000/ 2795 batches | loss 0.000090\n",
      "| epoch  16 |  2000/ 2795 batches | loss 0.000089\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time: 17.18s | train loss 0.000090 | validation loss 0.000094 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |  1000/ 2795 batches | loss 0.000089\n",
      "| epoch  17 |  2000/ 2795 batches | loss 0.000087\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time: 17.59s | train loss 0.000088 | validation loss 0.000090 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |  1000/ 2795 batches | loss 0.000087\n",
      "| epoch  18 |  2000/ 2795 batches | loss 0.000087\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time: 17.41s | train loss 0.000087 | validation loss 0.000088 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |  1000/ 2795 batches | loss 0.000085\n",
      "| epoch  19 |  2000/ 2795 batches | loss 0.000085\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time: 17.41s | train loss 0.000085 | validation loss 0.000086 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |  1000/ 2795 batches | loss 0.000084\n",
      "| epoch  20 |  2000/ 2795 batches | loss 0.000083\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time: 17.20s | train loss 0.000083 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  21 |  1000/ 2795 batches | loss 0.000083\n",
      "| epoch  21 |  2000/ 2795 batches | loss 0.000082\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  21 | time: 16.94s | train loss 0.000082 | validation loss 0.000086 \n",
      "-----------------------------------------------------------\n",
      "| epoch  22 |  1000/ 2795 batches | loss 0.000082\n",
      "| epoch  22 |  2000/ 2795 batches | loss 0.000082\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  22 | time: 17.93s | train loss 0.000082 | validation loss 0.000085 \n",
      "-----------------------------------------------------------\n",
      "| epoch  23 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  23 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  23 | time: 17.83s | train loss 0.000081 | validation loss 0.000085 \n",
      "-----------------------------------------------------------\n",
      "| epoch  24 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  24 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  24 | time: 17.71s | train loss 0.000081 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  25 |  1000/ 2795 batches | loss 0.000082\n",
      "| epoch  25 |  2000/ 2795 batches | loss 0.000082\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  25 | time: 17.88s | train loss 0.000082 | validation loss 0.000085 \n",
      "-----------------------------------------------------------\n",
      "| epoch  26 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  26 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  26 | time: 18.62s | train loss 0.000081 | validation loss 0.000085 \n",
      "-----------------------------------------------------------\n",
      "| epoch  27 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  27 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  27 | time: 18.28s | train loss 0.000080 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  28 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  28 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  28 | time: 17.75s | train loss 0.000080 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  29 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  29 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  29 | time: 18.32s | train loss 0.000081 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  30 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  30 |  2000/ 2795 batches | loss 0.000082\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  30 | time: 18.12s | train loss 0.000081 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  31 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  31 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  31 | time: 18.30s | train loss 0.000080 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  32 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  32 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  32 | time: 18.00s | train loss 0.000080 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  33 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  33 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  33 | time: 17.95s | train loss 0.000080 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  34 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  34 |  2000/ 2795 batches | loss 0.000081\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  34 | time: 17.81s | train loss 0.000080 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  35 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  35 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  35 | time: 17.83s | train loss 0.000080 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  36 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  36 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  36 | time: 17.90s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  37 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  37 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  37 | time: 18.68s | train loss 0.000079 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  38 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  38 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  38 | time: 17.96s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  39 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  39 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  39 | time: 18.35s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  40 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  40 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  40 | time: 17.98s | train loss 0.000079 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  41 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  41 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  41 | time: 17.93s | train loss 0.000078 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  42 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  42 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  42 | time: 17.98s | train loss 0.000079 | validation loss 0.000084 \n",
      "-----------------------------------------------------------\n",
      "| epoch  43 |  1000/ 2795 batches | loss 0.000080\n",
      "| epoch  43 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  43 | time: 17.80s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  44 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  44 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  44 | time: 18.02s | train loss 0.000079 | validation loss 0.000081 \n",
      "-----------------------------------------------------------\n",
      "| epoch  45 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  45 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  45 | time: 18.23s | train loss 0.000079 | validation loss 0.000081 \n",
      "-----------------------------------------------------------\n",
      "| epoch  46 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  46 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  46 | time: 18.26s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  47 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  47 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  47 | time: 18.22s | train loss 0.000079 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  48 |  1000/ 2795 batches | loss 0.000081\n",
      "| epoch  48 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  48 | time: 18.21s | train loss 0.000080 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  49 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  49 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  49 | time: 17.87s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  50 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  50 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  50 | time: 18.24s | train loss 0.000079 | validation loss 0.000080 \n",
      "-----------------------------------------------------------\n",
      "| epoch  51 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  51 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  51 | time: 18.17s | train loss 0.000079 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  52 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  52 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  52 | time: 17.67s | train loss 0.000079 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  53 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  53 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  53 | time: 18.01s | train loss 0.000079 | validation loss 0.000080 \n",
      "-----------------------------------------------------------\n",
      "| epoch  54 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  54 |  2000/ 2795 batches | loss 0.000078\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  54 | time: 17.67s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  55 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  55 |  2000/ 2795 batches | loss 0.000077\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  55 | time: 17.97s | train loss 0.000078 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "| epoch  56 |  1000/ 2795 batches | loss 0.000079\n",
      "| epoch  56 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  56 | time: 17.82s | train loss 0.000079 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  57 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  57 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  57 | time: 18.18s | train loss 0.000078 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  58 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  58 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  58 | time: 18.44s | train loss 0.000078 | validation loss 0.000083 \n",
      "-----------------------------------------------------------\n",
      "| epoch  59 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  59 |  2000/ 2795 batches | loss 0.000079\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  59 | time: 18.18s | train loss 0.000078 | validation loss 0.000081 \n",
      "-----------------------------------------------------------\n",
      "| epoch  60 |  1000/ 2795 batches | loss 0.000078\n",
      "| epoch  60 |  2000/ 2795 batches | loss 0.000080\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  60 | time: 17.74s | train loss 0.000079 | validation loss 0.000082 \n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test loss 0.000074\n"
     ]
    }
   ],
   "source": [
    "for i,config in enumerate(configs):\n",
    "\n",
    "    logging.info(\"| Experiment {} | embed dim: {}\".format(i + offset,config[\"embed_dim\"]))\n",
    "\n",
    "    # Train\n",
    "    model = Autoencoder(len(vocab), config[\"embed_dim\"])\n",
    "    train_autoencoder(model, train_dataloader, val_dataloader, epochs=EPOCHS, log_file=\"autoencoder.log\")\n",
    "\n",
    "    # Evaluate\n",
    "    print('Checking the results of test dataset.')\n",
    "    loss_test = evaluate_autoencoder(model, test_dataloader, MSELoss())\n",
    "    logging.info(\"| test accuracy {:8.6f} \".format(loss_test))\n",
    "    print('test loss {:8.6f}'.format(loss_test))\n",
    "\n",
    "    # Save\n",
    "    torch.save(model.state_dict(), f\"../data/models/autoencoder-{config['embed_dim']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79d364cbb5ff81f54abd98f9f83d50f90d379b8661ccc369e0ce6b6f261137f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
