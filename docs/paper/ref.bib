@book{Goodfellow-et-al-2016,
  title={Deep Learning},
  author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  publisher={MIT Press},
  note={\url{http://www.deeplearningbook.org}},
  year={2016}
}

@book{murphy2012machine,
  title={Machine learning: a probabilistic perspective},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}

@book{mitchell1997machine,
  title={Machine learning},
  author={Tom M. Mitchell},
  volume={1},
  number={9},
  year={1997},
  publisher={McGraw-hill New York}
}

@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}

@misc{jigsaw-toxic-comment-classification-challenge,
    author = {cjadams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, nithum, Will Cukierski},
    title = {Toxic Comment Classification Challenge},
    publisher = {Kaggle},
    year = {2017},
    url = {https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge}
}

@article{Honnibal_spaCy_Industrial-strength_Natural_2020,
author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
doi = {10.5281/zenodo.1212303},
title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
year = {2020}
}

@article{DBLP:journals/corr/abs-1912-01703,
  author    = {Adam Paszke and
               Sam Gross and
               Francisco Massa and
               Adam Lerer and
               James Bradbury and
               Gregory Chanan and
               Trevor Killeen and
               Zeming Lin and
               Natalia Gimelshein and
               Luca Antiga and
               Alban Desmaison and
               Andreas K{\"{o}}pf and
               Edward Z. Yang and
               Zach DeVito and
               Martin Raison and
               Alykhan Tejani and
               Sasank Chilamkurthy and
               Benoit Steiner and
               Lu Fang and
               Junjie Bai and
               Soumith Chintala},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal   = {CoRR},
  volume    = {abs/1912.01703},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.01703},
  eprinttype = {arXiv},
  eprint    = {1912.01703},
  timestamp = {Tue, 02 Nov 2021 15:18:32 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1803-08375,
  author    = {Abien Fred Agarap},
  title     = {Deep Learning using Rectified Linear Units (ReLU)},
  journal   = {CoRR},
  volume    = {abs/1803.08375},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.08375},
  eprinttype = {arXiv},
  eprint    = {1803.08375},
  timestamp = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-08375.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{coates,
author = {Coates, Adam and Ng, Andrew and Lee, Honglak},
year = {2011},
month = {01},
pages = {215-223},
title = {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
volume = {15},
journal = {Journal of Machine Learning Research - Proceedings Track}
}

@article{sarveniazi,
author = {Sarveniazi, Alireza},
year = {2014},
month = {01},
pages = {55-72},
title = {An Actual Survey of Dimensionality Reduction},
volume = {04},
journal = {American Journal of Computational Mathematics},
doi = {10.4236/ajcm.2014.42006}
}

@Inbook{Coates2012,
author="Coates, Adam
and Ng, Andrew Y.",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Learning Feature Representations with K-Means",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="561--580",
abstract="Many algorithms are available to learn deep hierarchies of features from unlabeled data, especially images. In many cases, these algorithms involve multi-layered networks of features (e.g., neural networks) that are sometimes tricky to train and tune and are difficult to scale up to many machines effectively. Recently, it has been found that K-means clustering can be used as a fast alternative training method. The main advantage of this approach is that it is very fast and easily implemented at large scale. On the other hand, employing this method in practice is not completely trivial: K-means has several limitations, and care must be taken to combine the right ingredients to get the system to work well. This chapter will summarize recent results and technical tricks that are needed to make effective use of K-means clustering for learning large-scale representations of images. We will also connect these results to other well-known algorithms to make clear when K-means can be most useful and convey intuitions about its behavior that are useful for debugging and engineering new systems.",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_30",
url="https://doi.org/10.1007/978-3-642-35289-8_30"
}

@article{DBLP:journals/corr/abs-1206-5538,
  author    = {Yoshua Bengio and
               Aaron C. Courville and
               Pascal Vincent},
  title     = {Unsupervised Feature Learning and Deep Learning: {A} Review and New
               Perspectives},
  journal   = {CoRR},
  volume    = {abs/1206.5538},
  year      = {2012},
  url       = {http://arxiv.org/abs/1206.5538},
  eprinttype = {arXiv},
  eprint    = {1206.5538},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1206-5538.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}